{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# The Marvel Comics Social Network\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project analyzes the relationships between characters in the Marvel comics as a social network. The source data provides insight into how often various characters meet throughout the comics, and in which comics they appear. The goal of this project is to use the source data to make predictions about future appearances of characters in Marvel Cinimatic Universe (MCU) movies based on character \"popularity\" from the original source comics. In addition, we will seek to derive social conclusions from the character relationships.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "`Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>`\n",
    "\n",
    "This project analyzes the relationships between characters in the Marvel comics as if they were people in a real social network. The source data provides insight into how often various characters meet throughout the comics, and in which comics they appear. This information could be used to assess which characters are the most \"popular\", by way of which character makes the most connections and appears in the most comics. Thinking of this in a \"social network\" context, we could make \"People You May Know\" recommendations for various characters with common connections (edges). The \"People You May Know\" output of this data exploration is similar to common functionality offered by other social media platforms, including Facebook, Instagram, LinkedIn, Twitter, and more.\n",
    "Also, by cross-referencing this information with character appearances in the Marvel Cinimatic Universe (MCU), we may be able to project which characters are most likely to next appear in the upcoming Marvel movies based on character \"popularity\" in the comics.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "`Describe the data sets you're using. Where did it come from? What type of information is included?`\n",
    "\n",
    "The source data is located in the `marvel_data` directory. The three main CSV files were sourced from [The Marvel Universe Social Network dataset on Kaggle](https://www.kaggle.com/csanhueza/the-marvel-universe-social-network). These files, along with a description of their contents, follows:\n",
    "- edges.csv: Indicates which comics that each hero appears in.\n",
    "- hero-network.csv: Indicates which heroes appear together in the comics.\n",
    "- nodes.csv: Describes the node types (i.e. either \"hero\" or \"comic\").\n",
    "\n",
    "The final CSV (screentime.csv) was gathered from [an MCU quiz on Sporkle](https://www.sporcle.com/games/wearevenom2/mcu-screen-time-2021). It contains the screentime for each comic book character in the Marvel Cinematic Universe (MCU) movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hero: string (nullable = true)\n",
      " |-- comic: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hero1: string (nullable = true)\n",
      " |-- hero2: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Screen Time: string (nullable = true)\n",
      " |-- Answer: string (nullable = true)\n",
      " |-- MCU Debut: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in the data here\n",
    "\n",
    "# Get source data folder\n",
    "source_file_path = os.getcwd() + '/marvel_data'\n",
    "edges_file_path = source_file_path + '/edges.csv'\n",
    "hero_network_file_path = source_file_path + '/hero-network.csv'\n",
    "nodes_file_path = source_file_path + '/nodes.csv'\n",
    "screentime_file_path = source_file_path + '/screentime.csv'\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "comic_appearances_df = spark.read.csv(edges_file_path, header='true')\n",
    "directed_hero_network_df = spark.read.csv(hero_network_file_path, header='true')\n",
    "screentime_df = spark.read.csv(screentime_file_path, header='true')\n",
    "\n",
    "comic_appearances_df.printSchema()\n",
    "directed_hero_network_df.printSchema()\n",
    "screentime_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "`Identify data quality issues, like missing values, duplicate data, etc.`\n",
    "\n",
    "1. Hero names don't match up between the \"Screentime\" table and the other tables, due to them coming from different sources.\n",
    "\n",
    "2. Hero names in the hero-network.csv source are truncated.\n",
    "\n",
    "3. Some characters in the \"Screentime\" table are not present as \"Heroes\" in the other tables because they are supporting characters, not heroes.\n",
    "\n",
    "#### Cleaning Steps\n",
    "`Document steps necessary to clean the data`\n",
    "\n",
    "1. Here, I provide a map to standardize the hero names in the screentime table to have the names from the other tables, for consistency and cross-referencing the hero names as foreign keys between the tables. I don't include all names for now, to save time, but as time permits, I will finish this mapping.\n",
    "\n",
    "2. This will require queries using \"LIKE%\" instead of \"=\". Also, names don't always align across tables. For instance, the nodes.csv has Spider-man as \"SPIDER-MAN/PETER PARKERKER\" (typo with \"KER\" repeated twice at the end), but the edges.csv table has him as \"SPIDER-MAN/PETER PARKER\" (correct spelling) and the hero-network.csv table has him as \"SPIDER-MAN/PETER PAR\" (truncated). This will require some tweaking of the data along the way. If results seem unintuitive, I will compare the hero and comic names and correct as I go.\n",
    "\n",
    "3. This does not require cleanup, but is just additional information. It may result in some NULL values in derived tables, but that is expected. We will have to filter out NULL values in any analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiderman entries per table:\n",
      "---------------------------\n",
      "\n",
      "Edges table:\n",
      "+-----------------------+\n",
      "|hero                   |\n",
      "+-----------------------+\n",
      "|SPIDER-MAN/PETER PARKER|\n",
      "+-----------------------+\n",
      "\n",
      "Hero Network table:\n",
      "+--------------------+\n",
      "|hero1               |\n",
      "+--------------------+\n",
      "|SPIDER-MAN/PETER PAR|\n",
      "+--------------------+\n",
      "\n",
      "Nodes table (Screentime table, after mapping):\n",
      "+--------------------+\n",
      "|Answer              |\n",
      "+--------------------+\n",
      "|SPIDER-MAN/PETER PAR|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "# Cleaning Step #1\n",
    "def map_names(old_name):\n",
    "    \"\"\"\n",
    "    Allows for mapping hero names from the Screentime source data table to those used in the Nodes source data table.\n",
    "    \"\"\"\n",
    "    \n",
    "    name_map = {\n",
    "        'Iron Man': 'IRON MAN/TONY STARK',\n",
    "        'Captain America': 'CAPTAIN AMERICA',\n",
    "        'Loki': 'LOKI [ASGARDIAN]',\n",
    "        'Thor': 'THOR/DR. DONALD BLAK',\n",
    "        'Black Widow': 'BLACK WIDOW/NATASHA',\n",
    "        'Spider-Man': 'SPIDER-MAN/PETER PAR',\n",
    "        'Scarlet Witch': 'SCARLET WITCH/WANDA',\n",
    "        'Falcon': 'FALCON/SAM WILSON',\n",
    "        'Winter Soldier': 'BUCKY/BUCKY BARNES',\n",
    "        'Ant-Man': 'ANT-MAN II/SCOTT HAR',\n",
    "        'Vision': 'VISION',\n",
    "        'Doctor Strange': 'DR. STRANGE/STEPHEN',\n",
    "        'Gamora': 'GAMORA',\n",
    "        'Captain Marvel': 'CAPTAIN MARVEL/CAPTA',\n",
    "        'Pepper Potts': 'POTTS, VIRGINIA PEPP',\n",
    "        'Nick Fury': 'FURY, COL. NICHOLAS',\n",
    "        'Black Panther': \"BLACK PANTHER/T'CHAL\",\n",
    "        'War Machine': 'RHODES, MR.',\n",
    "        'Rocket Raccoon': 'ROCKET RACCOON',\n",
    "        'Wasp': 'WASP/JANET VAN DYNE',\n",
    "        'Hawkeye': 'HAWKEYE/CLINT BARTON',\n",
    "        'Thanos': 'THANOS',\n",
    "        \n",
    "#         'Tinkerer': 'TINKERER',\n",
    "#         'Ayesha': 'AYESHA',\n",
    "#         'Minn-Erva': 'MINERVA [KREE]',\n",
    "#         'Supreme Intelligence': 'SUPREME INTELLIGENCE',\n",
    "#         'The Other': 'OTHER',\n",
    "#         'Morgan Stark': 'STARK, MORGAN',\n",
    "#         'Ellen Brandt': 'BRANDT, ELLEN',\n",
    "#         'Surtur': 'SURTUR'\n",
    "    }\n",
    "    return name_map[old_name] if old_name in name_map else old_name\n",
    "\n",
    "\n",
    "map_names_udf = f.udf(map_names)\n",
    "screentime_df = screentime_df.withColumn(\"Answer\", map_names_udf(\"Answer\"))\n",
    "\n",
    "\n",
    "# \"Cleaning\" Step #2\n",
    "print(\"Spiderman entries per table:\")\n",
    "print(\"---------------------------\\n\")\n",
    "print(\"Edges table:\")\n",
    "comic_appearances_df.select(\"hero\").filter(f.col(\"hero\").contains(\"SPIDER-MAN/PETER\")).distinct().show(5, False)\n",
    "\n",
    "print(\"Hero Network table:\")\n",
    "directed_hero_network_df.select(\"hero1\").filter(f.col(\"hero1\").contains(\"SPIDER-MAN/PETER\")).distinct().show(5, False)\n",
    "\n",
    "print(\"Nodes table (Screentime table, after mapping):\")\n",
    "screentime_df.select(\"Answer\").filter(f.col(\"Answer\").contains(\"SPIDER-MAN\")).distinct().show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "`Map out the conceptual data model and explain why you chose that model`\n",
    "\n",
    "The [schema diagram](./schema_diagram.png) illustrates the data model. An asterisk (*) indicates a primary key, and multiple asterisks on a single table indicate a composite primary key.\n",
    "This data model uses a Star schema with fact and dimension tables.\n",
    "The \"comic_appearances\" table is the fact table, as the fact of this data model is which heroes appeared in which comics. The combination of hero and comic is unique in the \"comic_appearances\" table, so those two fields together form the composite primary key.\n",
    "The \"screentime\" table is a dimension of the data model. The hero name is the primary key here, and also the foreign key from the \"comic_appearances\" table.\n",
    "The \"directed_network\" table is a dimension based off the hero_network source CSV. This table may have duplicate entries, and is treated more as a graph source than as a normalized database table. For that reason, there is no primary key.\n",
    "The \"undirected_network\" table is derived from the \"directed_network\" table. However, it is separated into its own table to improve the ability to query the database for valuable information. For instance, in this project, we assume that a hero's \"popularity\" is dependent on their interactions with others, but not on the direction of those interactions. By transforming the hero_network source CSV into both a directed and undirected network table, we preserve the data integrity of the source data in the directed_network table while improving the time to perform common queries from the undirected_network table. Going forward in our use of this database, we would need to insert hero interactions into each table. This improvement to querying the database would come at the expense of some database write performance, but this is a tradeoff we're willing to make, based on the assumption that we will be drawing analytics about character relationships much more often than we will be writing new interactions to the database.\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "`List the steps necessary to pipeline the data into the chosen data model`\n",
    "\n",
    "First, the edges.csv should be read into the \"comic_appearances\" table.\n",
    "\n",
    "Next, the screentime.csv should be read into a \"screentime\" table. I choose to rename the column labels on this table to remove spaces and standardize the language. I also chose to parse the initial time string from \"mm:ss\" format into just \"ss\" format, to facilitate numeric operations on the duration. This requires parsing the time by splitting the string on the \":\", multiplying the \"mm\" portion by 60, and adding that to the \"ss\" value.\n",
    "\n",
    "Then, the hero-network.csv should be read into the \"directed_hero_network\" table.\n",
    "\n",
    "Finally, the \"hero_network\" dataframe must be parsed to generate the \"undirected_hero_network\" table. This step includes:\n",
    "1. Standardize the order of the hero relationships. i.e. Remove the \"directed\" nature of the network.\n",
    "This step will require comparing hero1 and hero2 alphabetically and putting the alphabetically-first hero in the hero1 column and and the second hero in the hero2 column. This will standardize entries such as \"A -> B\" and \"B -> A\" to both be \"A -> B\". This will remove the directed nature of the network in the table.\n",
    "2. Removing duplicates\n",
    "Once each relationship is stored in alphabetical order, we can aggregate by each hero1-hero2 pair and add a \"sum\" column to count how many times each interaction occurred. This essentially removes duplicates, while maintaining the magnitude of interactions in the \"sum\" column. This table can then be more easily queried for network relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "`Build the data pipelines to create the data model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- hero: string (nullable = true)\n",
      " |-- debut_movie: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- hero1: string (nullable = true)\n",
      " |-- hero2: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- first_hero: string (nullable = true)\n",
      " |-- second_hero: string (nullable = true)\n",
      " |-- interactions_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "\n",
    "comic_appearances_df.createOrReplaceTempView(\"comic_appearances\")\n",
    "\n",
    "screentime_df = screentime_df.withColumnRenamed('Answer', 'hero')\\\n",
    "                    .withColumnRenamed('Screen Time', 'duration')\\\n",
    "                    .withColumnRenamed('MCU Debut', 'debut_movie')\n",
    "\n",
    "def duration_to_seconds(duration_string):\n",
    "    \"\"\"\n",
    "    Converts duration string from \"mm:ss\" string format to \"ss\" integer format \n",
    "    \"\"\"\n",
    "    \n",
    "    parts = duration_string.split(\":\")\n",
    "    seconds = (int(parts[0]) * 60) + int(parts[1])\n",
    "    return seconds\n",
    "\n",
    "duration_to_seconds_udf = f.udf(duration_to_seconds)\n",
    "screentime_df = screentime_df.withColumn(\"duration\", duration_to_seconds_udf(\"duration\").cast(\"int\"))\n",
    "\n",
    "screentime_df.printSchema()\n",
    "screentime_df.createOrReplaceTempView(\"screentime\")\n",
    "\n",
    "undirected_hero_network_df = directed_hero_network_df.withColumn(\"first_hero\", f.when(f.col(\"hero1\") < f.col(\"hero2\"), f.col(\"hero1\")).otherwise(f.col(\"hero2\")))\\\n",
    "                                                    .withColumn(\"second_hero\", f.when(f.col(\"hero1\") > f.col(\"hero2\"), f.col(\"hero1\")).otherwise(f.col(\"hero2\")))\\\n",
    "                                                    .drop(\"hero1\").drop(\"hero2\")\n",
    "undirected_hero_network_df = undirected_hero_network_df.groupBy(\"first_hero\", \"second_hero\").count().withColumnRenamed('count', 'interactions_count')\n",
    "\n",
    "directed_hero_network_df.printSchema()\n",
    "undirected_hero_network_df.printSchema()\n",
    "\n",
    "directed_hero_network_df.createOrReplaceTempView(\"directed_hero_network\")\n",
    "undirected_hero_network_df.createOrReplaceTempView(\"undirected_hero_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "```\n",
    "Explain and run the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    "```\n",
    "\n",
    "##### 4.2.1. Integrity constraints:\n",
    "First, I check the screentime table for the datatype of the duration column. I do this because the \"screentime\" is initially stored as a string in the source data, so this check allows me to validate my \"duration_to_seconds\" udf transformer to some degree.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "# Check the screentime table has a \"int\" type duration column, since it begins as a string in the source data.\n",
    "\n",
    "def check_field_data_type(table, field, expected):\n",
    "\n",
    "    field_entry = spark.sql(f'''\n",
    "        SELECT {field}\n",
    "        FROM {table}\n",
    "        WHERE {field} IS NOT NULL\n",
    "        LIMIT 1\n",
    "    ''').head()\n",
    "    \n",
    "    if field_entry is None:\n",
    "        raise AssertionError\n",
    "        return False\n",
    "    else: \n",
    "        field_entry = field_entry[0]\n",
    "    \n",
    "    assert isinstance(field_entry, expected), f\"Column '{field}' in table '{table}' is not {expected} type.\"\n",
    "    return isinstance(field_entry, expected)\n",
    "    \n",
    "print(check_field_data_type('screentime', 'duration', int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next, I join the screentime table with the undirected network table to validate that I get expected NULL duration results for a hero who has not yet appeared in MCU movies (i.e. screentime duration = NULL) but who do have undirected hero network interactions. At the same time, I validate that I get non-NULL duration results for a hero who I know to have appeared in MCU movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check the screentime duration value for a given hero name. Some may be NULL.\n",
    "\n",
    "def check_hero_movie_duration(hero_name, expected_duration):\n",
    "\n",
    "    field_entry = spark.sql(f'''\n",
    "        SELECT un.first_hero, st.duration, SUM(un.interactions_count) interactions\n",
    "        FROM undirected_hero_network un\n",
    "        LEFT JOIN screentime st ON (un.first_hero = st.hero)\n",
    "        WHERE un.first_hero = \"{hero_name}\"\n",
    "        GROUP BY un.first_hero, st.duration\n",
    "        ORDER BY st.duration DESC, interactions DESC\n",
    "        LIMIT 1\n",
    "    ''').head()\n",
    "    \n",
    "    if field_entry is None:\n",
    "        raise AssertionError('No entry found.')\n",
    "        return False\n",
    "    else: \n",
    "        field_entry = field_entry[1]\n",
    "        \n",
    "    field_entry = 0 if field_entry is None else field_entry\n",
    "    \n",
    "    assert field_entry == expected_duration, f\"{hero_name} has {field_entry} screentime duration, not {expected_duration}.\"\n",
    "    return field_entry == expected_duration\n",
    "    \n",
    "print(check_hero_movie_duration('CAPTAIN AMERICA', 14610))\n",
    "print(check_hero_movie_duration('BEAST/HENRY &HANK& P', 0))\n",
    "print(check_hero_movie_duration('IRON MAN/TONY STARK ', 0))\n",
    "# print(check_hero_movie_duration('IRON MAN/TONY STARK', 0))  # Expected to throw an assertion error. Name not found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "These results reveal something interesting. Iron Man has the most screentime duration according to the screentime table, but does not appear at the top of the joined table, even when we sort by duration descending. This reveals the data error that Iron Man is stored under different names in the two tables. On closer inspection, the name has a space (' ') character at the end in the undirected_hero_network table. This error in the source data would have to be corrected upstream, prior to loading the dataframe data into the SQL tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.2. Unit test scripts:\n",
    "I perform simple unit tests for the map_names and duration_to_seconds udf transformer functions outside of a dataframe and with known values, to validate their operation.\n",
    "For completeness, I use the previous test function to perform a search in the screentime table on a hero name that was translated from the edges.csv to ensure that the map_names udf function was properly performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Validate the map_names udf functionality\n",
    "assert map_names(\"Spider-Man\") == \"SPIDER-MAN/PETER PAR\", \"Unexpected value received from map_names converter.\"\n",
    "print(map_names(\"Spider-Man\") == \"SPIDER-MAN/PETER PAR\")\n",
    "\n",
    "# Validate the duration_to_seconds udf functionality\n",
    "assert duration_to_seconds(\"10:30\") == 630, \"Unexpected value received from duration_to_seconds converter.\"\n",
    "print(duration_to_seconds(\"10:30\") == 630)\n",
    "\n",
    "# Use a transformed hero name to check for the user in the screentime table\n",
    "print(check_hero_movie_duration('SPIDER-MAN/PETER PAR', 9750))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### 4.2.3. Soure/Count checks: \n",
    "I perform a filter on the directed_hero_network for a hero with both initiating and receiving interactions in the hero-network source. I then perform the same filter in the undirected_hero_network table to ensure that the number of row results in the directed_hero_network table filter matches the \"interactions_count\" value in the undirected_hero_network table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Compare number of interaction rows in the directed interaction table to the counts in the undirected interaction table\n",
    "\n",
    "def get_directed_hero_interaction_count(hero1, hero2):\n",
    "\n",
    "    interactions = spark.sql(f'''\n",
    "        SELECT hero1, hero2\n",
    "        FROM directed_hero_network\n",
    "        WHERE (hero1='{hero1}' OR hero2='{hero1}') AND (hero1='{hero2}' OR hero2='{hero2}')\n",
    "        ORDER BY hero1 ASC\n",
    "    ''').count()\n",
    "    \n",
    "    return interactions\n",
    "\n",
    "def get_undirected_hero_interaction_count(hero1, hero2):\n",
    "\n",
    "    interactions = spark.sql(f'''\n",
    "        SELECT first_hero, second_hero, interactions_count\n",
    "        FROM undirected_hero_network\n",
    "        WHERE (first_hero='{hero1}' OR second_hero='{hero1}') AND (first_hero='{hero2}' OR second_hero='{hero2}')\n",
    "        ORDER BY first_hero ASC\n",
    "    ''').head()[2]\n",
    "    \n",
    "    return interactions\n",
    "\n",
    "directed_count = get_directed_hero_interaction_count('DOLLAR BILL', 'CLEA')\n",
    "undirected_count = get_undirected_hero_interaction_count('DOLLAR BILL', 'CLEA')\n",
    "assert directed_count == undirected_count, \"The directed and undirected interaction counts for the heroes provided do not align.\"\n",
    "print(directed_count == undirected_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "`Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.`\n",
    "\n",
    "\"comic_appearances\" table\n",
    "\n",
    "| Row         | Data Type                    | Description                      | Source      |\n",
    "| ----------- | ---------------------------- | -------------------------------- | ----------- |\n",
    "| hero        | string (all caps, truncated) | Hero Name                        | edges.csv   |\n",
    "| comic       | string (all caps)            | Comic Title (Series and Edition) | edges.csv   |\n",
    "\n",
    "\n",
    "\"screentime\" table\n",
    "\n",
    "| Row         | Data Type | Description                                | Source           |\n",
    "| ----------- | --------- | ------------------------------------------ | ---------------- |\n",
    "| hero        | string    | Hero Name                                  | screentime.csv   |\n",
    "| duration    | int       | Screen time in MCU movies (in seconds)     | screentime.csv   |\n",
    "| debut_movie | string    | First movie that the character appeared in | screentime.csv   |\n",
    "\n",
    "\n",
    "\"directed_hero_network\" table\n",
    "\n",
    "| Row      | Data Type | Description                     | Source             |\n",
    "| -------- | --------- | ------------------------------- | ------------------ |\n",
    "| hero1    | string    | Hero initiating the interaction | hero-network.csv   |\n",
    "| hero2    | string    | Hero receiving the interaction  | hero-network.csv   |\n",
    "\n",
    "\n",
    "\"undirected_hero_network\" table\n",
    "\n",
    "| Row                | Data Type | Description                                            | Source             |\n",
    "| ------------------ | --------- | ------------------------------------------------------ | ------------------ |\n",
    "| first_hero         | string    | One of the heroes in the interation                    | hero-network.csv   |\n",
    "| second_hero        | string    | One of the heroes in the interation                    | hero-network.csv   |\n",
    "| interactions_count | int       | Number of recorded interactions between the two heroes | hero-network.csv   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "```\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This project was chosen to explore my interest in Marvel movies in a context with social media applicability. I chose to use Apache Spark for its simplicity in extracting CSV data, transforming it in dataframes, and loading it into SQL tables.\n",
    "\n",
    "Also, since this project simulates social network functionality, which is an excellent choice for running on a distributed network, Spark is an excellent technology choice, as it can be easily configured to run on a distributed cluster. I ultimately chose not to actually execute this pipeline on an AWS cluster, due to a lack of AWS credits remaining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The initial data import gets the database up-to-date with the current state of hero relationships in the MCU movies and Marvel comics. Going forward, it would be sufficient to update the data once per day, during low-traffic hours. User relationship data is not more time-sensitive than per day, so it should be enough to have an updated representation of user relationships daily, for making new relationship recommendations and for deriving new analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "If the data was increased by 100x, I would partition the data by hero. Individual users have less frequent interactions than a large mass of user. This partioning would support hero-based queries, including relationship recommendations and analytics around hero inclusion in the MCU movies.\n",
    "Partitioning the data helps with storage and organization, but we can also make improvements to processing the data at a larger scale. Spark can process the results in parallel across several cores. While this parallelization can occur locally, it is more beneficial to execute these queries, analytics, and processes on a remote, distributed cluster optimized for this purpose. I would likely execute analytics on an AWS Redshift cluster on the partitioned data. The cores, memory, and other parameters could be configured and scaled to grow or shrink easily with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "If a dashboard needed to be populated daily at 7am, I would use an Airflow pipeline. Airflow pipelines support scheduled tasks, and they could easily perform queries on the past day of new data entries, aggregate them into a larger repository of aggregated data, and report on the developments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "If the data needed to be accessed by 100+ people, I would implement an AWS cloud data warehouse. A distributed database network could be accessed more easily globally. And while this would result in data duplication, it would improve data redundancy for data integrity and backup purposes while improving database read times. I would also implement a caching solution in front of the database at various levels (i.e. server, CDN, etc.) to improve read times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Analysis\n",
    "\n",
    "The initial purpose of this project was to analyze the relationships between heroes in the Marvel movies and comics. The data has several source inconsistencies, primarily with hero names, which make some analysis results a bit skewed, but we are still able to derive general takeaways from the project.\n",
    "\n",
    "One of the main questions initially was \"Who are some of the most prominent/active characters from the comics who have yet to debut in the Marvel movies?\". This question can be answered with the query below.\n",
    "\n",
    "Interestingly, it would seem that \"Beast\" and \"Human Torch\" are two of the top candidates for Marvel movie screentime, based on their interactions in the comics. However, it's important to remember that they have both appeared in several other movie franchises already. Beast has been prevalent in X-Men movies, and Human Torch has been in Fantastic Four movies. Thus, this dataset tells the story in regards to the MCU, but may be missing some data if we want to tell a broader picture about general screentime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------+\n",
      "|          first_hero|duration|interactions|\n",
      "+--------------------+--------+------------+\n",
      "|BEAST/HENRY &HANK& P|    null|        8589|\n",
      "|HUMAN TORCH/JOHNNY S|    null|        7356|\n",
      "|ANT-MAN/DR. HENRY J.|    null|        7273|\n",
      "|CYCLOPS/SCOTT SUMMER|    null|        7069|\n",
      "|ANGEL/WARREN KENNETH|    null|        6872|\n",
      "|COLOSSUS II/PETER RA|    null|        6798|\n",
      "|IRON MAN/TONY STARK |    null|        6606|\n",
      "|INVISIBLE WOMAN/SUE |    null|        5937|\n",
      "|                HAWK|    null|        5738|\n",
      "|HULK/DR. ROBERT BRUC|    null|        4858|\n",
      "|BLACK WIDOW/NATASHA |    null|        4438|\n",
      "|DR. STRANGE/STEPHEN |    null|        4177|\n",
      "|DAREDEVIL/MATT MURDO|    null|        4058|\n",
      "|MR. FANTASTIC/REED R|    null|        4013|\n",
      "|CANNONBALL II/SAM GU|    null|        3994|\n",
      "|   JAMESON, J. JONAH|    null|        3962|\n",
      "|HERCULES [GREEK GOD]|    null|        3634|\n",
      "|ICEMAN/ROBERT BOBBY |    null|        3606|\n",
      "|BLACK KNIGHT V/DANE |    null|        3461|\n",
      "|   CRYSTAL [INHUMAN]|    null|        3284|\n",
      "+--------------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most \"popular/active\" character who's not in the movies\n",
    "\n",
    "spark.sql('''\n",
    "    SELECT un.first_hero, st.duration, SUM(un.interactions_count) interactions\n",
    "    FROM undirected_hero_network un\n",
    "    LEFT JOIN screentime st ON (un.first_hero = st.hero)\n",
    "    WHERE duration IS NULL\n",
    "    GROUP BY un.first_hero, st.duration\n",
    "    ORDER BY st.duration DESC, interactions DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|                  h1|                  h2|interactions|\n",
      "+--------------------+--------------------+------------+\n",
      "|MISS AMERICA/MADELIN|   PATRIOT/JEFF MACE|        1894|\n",
      "|   PATRIOT/JEFF MACE|   PATRIOT/JEFF MACE|        1275|\n",
      "|HUMAN TORCH/JOHNNY S|THING/BENJAMIN J. GR|         744|\n",
      "|HUMAN TORCH/JOHNNY S|MR. FANTASTIC/REED R|         713|\n",
      "|MR. FANTASTIC/REED R|THING/BENJAMIN J. GR|         708|\n",
      "|INVISIBLE WOMAN/SUE |MR. FANTASTIC/REED R|         701|\n",
      "|HUMAN TORCH/JOHNNY S|INVISIBLE WOMAN/SUE |         694|\n",
      "|MISS AMERICA/MADELIN|MISS AMERICA/MADELIN|         672|\n",
      "|INVISIBLE WOMAN/SUE |THING/BENJAMIN J. GR|         668|\n",
      "|SPIDER-MAN/PETER PAR|WATSON-PARKER, MARY |         616|\n",
      "|   JAMESON, J. JONAH|SPIDER-MAN/PETER PAR|         526|\n",
      "|     CAPTAIN AMERICA|IRON MAN/TONY STARK |         446|\n",
      "|SCARLET WITCH/WANDA |             VISION |         422|\n",
      "|ANT-MAN/DR. HENRY J.|WASP/JANET VAN DYNE |         406|\n",
      "|CYCLOPS/SCOTT SUMMER|MARVEL GIRL/JEAN GRE|         390|\n",
      "|STORM/ORORO MUNROE S|    WOLVERINE/LOGAN |         389|\n",
      "|     CAPTAIN AMERICA|THOR/DR. DONALD BLAK|         386|\n",
      "|     CAPTAIN AMERICA|             VISION |         385|\n",
      "|     CAPTAIN AMERICA|WASP/JANET VAN DYNE |         384|\n",
      "|         PARKER, MAY|SPIDER-MAN/PETER PAR|         380|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Strongest relationship (sort by most interactions)\n",
    "\n",
    "spark.sql('''\n",
    "    SELECT un.first_hero h1, un.second_hero h2, un.interactions_count interactions\n",
    "    FROM undirected_hero_network un\n",
    "    ORDER BY interactions DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                  h1|associations|\n",
      "+--------------------+------------+\n",
      "|     CAPTAIN AMERICA|        1659|\n",
      "|BEAST/HENRY &HANK& P|        1184|\n",
      "|ANT-MAN/DR. HENRY J.|        1060|\n",
      "|ANGEL/WARREN KENNETH|        1053|\n",
      "|IRON MAN/TONY STARK |         896|\n",
      "|CYCLOPS/SCOTT SUMMER|         882|\n",
      "|HUMAN TORCH/JOHNNY S|         850|\n",
      "|BLACK WIDOW/NATASHA |         848|\n",
      "|COLOSSUS II/PETER RA|         840|\n",
      "|DR. STRANGE/STEPHEN |         822|\n",
      "|DAREDEVIL/MATT MURDO|         774|\n",
      "|INVISIBLE WOMAN/SUE |         758|\n",
      "|                HAWK|         746|\n",
      "|BLACK KNIGHT V/DANE |         674|\n",
      "|HULK/DR. ROBERT BRUC|         667|\n",
      "|BLACK PANTHER/T'CHAL|         656|\n",
      "|FURY, COL. NICHOLAS |         633|\n",
      "|HERCULES [GREEK GOD]|         623|\n",
      "|      JARVIS, EDWIN |         584|\n",
      "|MR. FANTASTIC/REED R|         583|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most popular hero by most associations\n",
    "\n",
    "spark.sql('''\n",
    "    SELECT un.first_hero h1, COUNT(un.interactions_count) associations\n",
    "    FROM undirected_hero_network un\n",
    "    GROUP BY h1\n",
    "    ORDER BY associations DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                  h1|interactions|\n",
      "+--------------------+------------+\n",
      "|     CAPTAIN AMERICA|       14188|\n",
      "|BEAST/HENRY &HANK& P|        8589|\n",
      "|HUMAN TORCH/JOHNNY S|        7356|\n",
      "|ANT-MAN/DR. HENRY J.|        7273|\n",
      "|CYCLOPS/SCOTT SUMMER|        7069|\n",
      "|ANGEL/WARREN KENNETH|        6872|\n",
      "|COLOSSUS II/PETER RA|        6798|\n",
      "|IRON MAN/TONY STARK |        6606|\n",
      "|INVISIBLE WOMAN/SUE |        5937|\n",
      "|                HAWK|        5738|\n",
      "|HULK/DR. ROBERT BRUC|        4858|\n",
      "|BLACK WIDOW/NATASHA |        4438|\n",
      "|DR. STRANGE/STEPHEN |        4177|\n",
      "|DAREDEVIL/MATT MURDO|        4058|\n",
      "|MR. FANTASTIC/REED R|        4013|\n",
      "|CANNONBALL II/SAM GU|        3994|\n",
      "|   JAMESON, J. JONAH|        3962|\n",
      "|HERCULES [GREEK GOD]|        3634|\n",
      "|ICEMAN/ROBERT BOBBY |        3606|\n",
      "|BLACK KNIGHT V/DANE |        3461|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Most popular hero by most interactions\n",
    "\n",
    "spark.sql('''\n",
    "    SELECT un.first_hero h1, SUM(un.interactions_count) interactions\n",
    "    FROM undirected_hero_network un\n",
    "    GROUP BY h1\n",
    "    ORDER BY interactions DESC\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "These prior two queries depict the difference between a character having a lot of back-and-forth interactions versus having interactions with many different characters. After the first few rows, the results vary widely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Acquaintance Referral Scenario\n",
    "\n",
    "In a social network, a realistic query analysis may be used to suggest a new relationship to a user. This can be done using the undirected_hero_network table. Assuming we are looking for a recommendation for a certain hero (say, Spider-Man), we can inspect the table to see who they interact with most. For now, let's call that hero \"Hero B\". Then, we can perform a query for Hero B's interactions, where we search for the first hero who does not appear to have any interactions with Spider-Man (call them, Hero C). We could then refer Hero C to Spider-Man as a referral. The logic here is that, if Spider-Man and Hero B have many interactions together, perhaps Spider-Man would be interested to know Hero C, who also has relatively many interactions with Hero B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_top_interaction(hero):\n",
    "    \"\"\"\n",
    "    Gets top interaction partner for a specified hero.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = spark.sql(f'''\n",
    "        SELECT un.second_hero\n",
    "        FROM undirected_hero_network un\n",
    "        WHERE un.first_hero = \"{hero}\" OR un.second_hero = \"{hero}\"\n",
    "        GROUP BY un.first_hero, un.second_hero\n",
    "        ORDER BY SUM(interactions_count) DESC\n",
    "        LIMIT 1\n",
    "    ''').head()[0]\n",
    "    return result\n",
    "\n",
    "def get_recommendations(main_hero, min_threshold=0, limit=5, show_interactions=False):\n",
    "    \"\"\"\n",
    "    Gets top recommendations for a hero's new acquaintance, based on the top interactions of that hero's top interaction partner.\n",
    "    \n",
    "    @param main_hero Name of the hero for whom recommendations are being retrieved.\n",
    "    @param min_threshold Minimum number of interactions that must occur for a recommendation to be made.\n",
    "    @param limit Max number of recommendations to make.\n",
    "    \n",
    "    @return array of recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Gathering recommendations for {main_hero}...\")\n",
    "    best_friend = get_top_interaction(main_hero)\n",
    "    print(f\"Top acquaintance of {main_hero} is {best_friend}.\")\n",
    "    \n",
    "    recommendations_df = spark.sql(f'''\n",
    "        SELECT best_friend_list.acquaintance, best_friend_list.interactions best_friend_interactions, main_hero_list.interactions main_hero_interactions FROM\n",
    "        (SELECT un.first_hero, un.second_hero, \n",
    "            CASE\n",
    "                WHEN un.first_hero = '{best_friend}'\n",
    "                THEN un.second_hero\n",
    "                ELSE un.first_hero\n",
    "                END as acquaintance,\n",
    "        SUM(interactions_count) interactions\n",
    "        FROM undirected_hero_network un\n",
    "        WHERE (un.first_hero = \"{best_friend}\" OR un.second_hero = \"{best_friend}\")\n",
    "        AND (un.interactions_count >= {min_threshold})\n",
    "        GROUP BY un.first_hero, un.second_hero\n",
    "        ORDER BY interactions DESC) best_friend_list\n",
    "        LEFT JOIN\n",
    "        (SELECT un.first_hero, un.second_hero,\n",
    "            CASE\n",
    "                WHEN un.first_hero = '{main_hero}'\n",
    "                THEN un.second_hero\n",
    "                ELSE un.first_hero\n",
    "                END as acquaintance,\n",
    "            SUM(interactions_count) interactions\n",
    "        FROM undirected_hero_network un\n",
    "        WHERE un.first_hero = \"{main_hero}\" OR un.second_hero = \"{main_hero}\"\n",
    "        GROUP BY un.first_hero, un.second_hero\n",
    "        ORDER BY interactions DESC) main_hero_list\n",
    "        ON best_friend_list.acquaintance = main_hero_list.acquaintance\n",
    "        WHERE main_hero_list.interactions IS NULL AND best_friend_list.acquaintance <> \"{main_hero}\"\n",
    "        ORDER BY best_friend_list.interactions DESC\n",
    "        LIMIT {limit}\n",
    "    ''')\n",
    "    \n",
    "    if show_interactions:\n",
    "        recommendations_df.show()\n",
    "\n",
    "    recommendations_list = [row['acquaintance'] for row in recommendations_df.collect()]\n",
    "    \n",
    "    return recommendations_list\n",
    "\n",
    "def display_recommendations(hero, rec_list):\n",
    "    print(f\"Top recommendations for {hero} are:\")\n",
    "    print(*rec_list, sep='\\n')\n",
    "\n",
    "spiderman_recs = get_recommendations(\"SPIDER-MAN/PETER PAR\", 0, 3)\n",
    "display_recommendations(\"Spider-Man\", spiderman_recs)\n",
    "\n",
    "cap_recs = get_recommendations(\"CAPTAIN AMERICA\", 5, 5, True)\n",
    "display_recommendations(\"Captain America\", cap_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "To break down this query: We use a subquery to get a list of acquaintainces to \"WATSON-PARKER, MARY\" (after querying the undirected_hero_network table for Spider-Man's top acquaintance, and getting that it is \"WATSON-PARKER, MARY\"). We also execute the same query to get the Spider-man filtered version of the undirected_hero_network table with the acquaintance name in a predetermined column. We then filter for instances where Spider-Man has no interactions (i.e. NULL) where \"WATSON-PARKER, MARY\" does have interactions with the acquaintance. Finally, we sort in descending order by \"WATSON-PARKER, MARY\"'s interactions, and filter out Spider-Man's entry as well (since he can't be his own acquaintance). This leaves us with a short list of two characters whom \"WATSON-PARKER, MARY\" interacted with and who Spider-Man did not. \"WATSON-PARKER, MARY\" has very few interactions with these characters (just one each), but if we were to make a recommendation to Spider-Man for a new acquaintance based on his strong relationship with \"WATSON-PARKER, MARY\", we would recommend them.\n",
    "\n",
    "Due to the low level of interactions depicted in this example between \"WATSON-PARKER, MARY\" and the recommended characters, I added several parameters to the recommendation function.\n",
    "\n",
    "First, I added an optional minimum threshold to acquaintance recommendations. If the secondary hero does not surpass that level of interaction with the \"recommended\" characters, then they won't be recommended. I also added an optional limit for an upper limit of how many recommendations to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Summary\n",
    "\n",
    "These examples demonstrate how the source dataset can be used to provide valuable insights into a social networking application. While it is assumed that a graph, rather than a relational database, is a better representation of nodes in a social network, this example utilizes the tools we've learned in this course with a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
